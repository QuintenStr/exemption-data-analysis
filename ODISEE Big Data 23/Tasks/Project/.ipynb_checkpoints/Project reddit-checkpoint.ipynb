{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e287572c",
   "metadata": {},
   "source": [
    "# Project big data\n",
    "\n",
    "Dit document bevat de opgave voor het project van het vak Big Data.\n",
    "Tijdens dit project gaan we een dataset van Kaggle halen om tekst te classificeren.\n",
    "Welke classificatie je wil uitvoeren is iets dat je zelf mag kiezen.\n",
    "Een aantal voorbeelden zijn:\n",
    "* Sentiment analyse\n",
    "* Sarcasme detectie\n",
    "* Hate speech detectie\n",
    "* Fake news detectie\n",
    "* ...\n",
    "\n",
    "Belangrijk hierbij is dat de volgende twee kolommen in je dataset aanwezig zijn:\n",
    "* Een kolom met een korte tekst\n",
    "* Een kolom met een label/target dat je wil classificeren\n",
    "\n",
    "Het doel is dan het getrainde model los te laten op een live-stream van reddit data en de classificatie uit te voeren.\n",
    "De resultaten van de classificatie worden dan opgeslaan in een NoSQL database.\n",
    "\n",
    "In grote lijnen zijn de te volgen stappen als volgt:\n",
    "* Upload een gekozen dataset naar Hadoop\n",
    "* Voer een analyse uit van de beschikbare gegevens door middel van Map Reduce\n",
    "* Verwerk en train de dataset met behulp van Spark en MLlib\n",
    "* Haal met een streaming service live data van reddit en laad het in met Spark (Spark Streaming, Kafka of Storm)\n",
    "* Voer classificatie uit en sla de resultaten op in een NoSQL Database\n",
    "* Haal een aantal resultaten op uit de NoSQL Database\n",
    "\n",
    "## Praktisch\n",
    "\n",
    "Bovenstaande opdracht voer je uit in **groepjes van max twee studenten**.\n",
    "\n",
    "Voor deze opdracht moeten de volgende zaken ingediend worden:\n",
    "* De code die je geschreven hebt voor de opdracht uit te voeren via deze github repo\n",
    "* Een presentatie voor de mondelinge verdediging via deze github repo (het kan zijn dat dit door omstandigheden wegvalt)\n",
    "\n",
    "De deadlines die aanwezig zijn voor het project zijn:\n",
    "* Samenstellen van de groepen, keuze bespreking van het onderwerp/doel van de classificatie: Deadline **eind tweede week**\n",
    "* Feedback over de reeds geschreven code van het project: **tijdens de les op 30 maart.**\n",
    "* Code deadline: **05/06/2023 om 23u59**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aeb539",
   "metadata": {},
   "source": [
    "## Stap 1: Beschrijving van het project\n",
    "\n",
    "Geef hieronder de namen van je groep in:\n",
    "* Team lid 1: Stroobants Quinten\n",
    "* Team lid 2: Danau Lorenzo\n",
    "\n",
    "Ga nu op zoek naar een dataset op Google of Kaggle om tekstverwerking te doen.\n",
    "Op Kaggle vind je vooral engelstalige teksten maar via Google is het ook mogelijk om Nederlandstalige datasets te vinden.\n",
    "[Dit](https://rdrr.io/github/weRbelgium/hatespeech.dutch/man/dutch_racistspeech.html) is een voorbeeld van een nederlandstalige dataset om racisme te detecteren in social media posts.\n",
    "Deze dataset moet gebruikt worden voor een classificatie taak uit te voeren.\n",
    "Dit houdt dus in dat er een kolom met tekst en een kolom met labels aanwezig moet zijn in de dataset.\n",
    "Het doel van deze classificatie is vrij te kiezen.\n",
    "Houd in rekening dat deze dataset gaat toegepast worden op social media data dus dat de tekst niet noodzakelijk heel lang moet zijn (het moeten dus geen hele boeken zijn).\n",
    "\n",
    "**Beschrijf hieronder de gekozen dataset en wat je ermee probeert te bereiken. Geef ook de datastructuur weer en welke kolommen je wilt gebruiken. Indien je niet zeker bent of de dataset die je gekozen hebt goed werkt, mag je me het me steeds vragen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914be2f3",
   "metadata": {},
   "source": [
    "We gaan werken met een dataset die verschillende kolommen heeft maar we hebben er maar 2 nodig. De text en het label. Bij het label heb je 0, 1, en 2. 0 is hate speech, 1 is offensive language en 2 is neither. Bij de text heb je de ruwe data van een 20 duizend tal tweets. (Deze word eerst wel nog gekuist om een beter model te trainen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bebb8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import opendatasets as od\n",
    "import re\n",
    "import pandas as pd\n",
    "import pydoop.hdfs as hdfs\n",
    "import statistics\n",
    "import os  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.classification import GBTClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f421f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./hate-speech-and-offensive-language-dataset\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# Dataset downloaden\n",
    "od.download('https://www.kaggle.com/mrmorj/hate-speech-and-offensive-language-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8c4c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing van de text (verbeteren voor model te trainen)\n",
    "def preprocess_tweet_text(tweet):\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    \n",
    "    # Replace &amp; with \"and\"\n",
    "    tweet = tweet.replace(\"&amp;\", \"and\")\n",
    "    \n",
    "    # Remove mentions and hashtags\n",
    "    tweet = re.sub(r\"@[^\\s]+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"#(\\w+)\", \"\", tweet)\n",
    "    \n",
    "    # Remove standalone \"RT\" mentions\n",
    "    tweet = re.sub(r\"(^|\\s)RT(\\s|$)\", \" \", tweet)\n",
    "    \n",
    "    # Remove non-ASCII characters\n",
    "    tweet = tweet.encode(\"ascii\", \"ignore\").decode()\n",
    "    \n",
    "    # Remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    tweet = emoji_pattern.sub(r\"\", tweet)\n",
    "    \n",
    "    # Remove other unwanted characters\n",
    "    tweet = re.sub(r\"[^a-zA-Z0-9]\", \" \", tweet)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    tweet = re.sub(r\"\\s+\", \" \", tweet).strip()\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8d4acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>as a woman you shouldn t complain about cleani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>boy dats cold tyga dwn bad for cuffin dat hoe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>dawg you ever fuck a bitch and she start to cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>the shit you hear about me might be true or it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you s a muthaf in lie right his tl is trash no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you ve gone and broke the wrong heart baby and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat dat nigguh like i aint fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ruffled ntac eileen dahlia beautiful color com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      as a woman you shouldn t complain about cleani...  \n",
       "1      boy dats cold tyga dwn bad for cuffin dat hoe ...  \n",
       "2      dawg you ever fuck a bitch and she start to cr...  \n",
       "3                                 she look like a tranny  \n",
       "4      the shit you hear about me might be true or it...  \n",
       "...                                                  ...  \n",
       "24778  you s a muthaf in lie right his tl is trash no...  \n",
       "24779  you ve gone and broke the wrong heart baby and...  \n",
       "24780  young buck wanna eat dat nigguh like i aint fu...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ruffled ntac eileen dahlia beautiful color com...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Csv in dataframe gieten en preprocessing applyen, exporten als cleaned.csv\n",
    "df = pd.read_csv('./hate-speech-and-offensive-language-dataset/labeled_data.csv')\n",
    "df['tweet'] = df['tweet'].apply(preprocess_tweet_text)\n",
    "\n",
    "display(df)\n",
    "df.to_csv('cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c84295c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 14:51:40,734 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Oefeningen/Project\n"
     ]
    }
   ],
   "source": [
    "# make links with local and hdfs file systems\n",
    "localFS = hdfs.hdfs(host='')\n",
    "client = hdfs.hdfs(host='localhost', port=9000)\n",
    "\n",
    "# if directory does not exists - make directory\n",
    "if not client.exists('/Oefeningen/Project'):\n",
    "    client.create_directory('/Oefeningen/Project')\n",
    "client.set_working_directory('/Oefeningen/Project')\n",
    "print(client.working_directory())\n",
    "\n",
    "# do some cleaning in case anything else than input.txt is present\n",
    "for f in client.list_directory(\".\"):\n",
    "    if not f[\"name\"].endswith(\"cleaned.csv\"):\n",
    "        client.delete(f[\"name\"], True) # True om aan te geven dat folders ook verwijderd moeten worden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf12c7",
   "metadata": {},
   "source": [
    "## Stap 2: Analyze van de dataset\n",
    "\n",
    "In deze fase van het project gaan we een stuk code schrijven om de gekozen dataset up te loaden naar de hadoop distributie van de Virtuele Machine gebruikt tijdens de les.\n",
    "\n",
    "Voorzie voldoende commentaar en maak gebruik van functies om de verschillende stappen op te delen en de structuur duidelijk te maken.\n",
    "\n",
    "Voer de volgende stappen uit in de code cell hieronder met de commentaar: \"# hdfs_deel 1\"\n",
    "* Upload de dataset naar een aparte directory met naam **Project**\n",
    "* Vraag de volgende algemene zaken op over dit bestand door middel van hdfs commando's of map reduce applicaties met pydoop\n",
    " * Bestandsgrootte\n",
    " * Aantal replica's\n",
    " * Aantal blocks\n",
    " * Het aantal kolommen aanwezig in de dataset\n",
    "* Verhoog het aantal replica's met twee. Vraag na aanpassing deze waarden terug op om het te verifieren. Is deze aanpassing gelukt? Indien niet, waarom niet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e24e057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hdfs deel 1\n",
    "localFS.copy(\"cleaned.csv\", client, \"cleaned.csv\") # upload file to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1023345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stap_1_analytics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stap_1_analytics.py\n",
    "\n",
    "import pydoop.mapreduce.api as api\n",
    "import pydoop.mapreduce.pipes as pipes\n",
    "\n",
    "class MyMapper(api.Mapper):            \n",
    "    # Dan aantal kolommen per rij mappen    \n",
    "    def map(self, context):\n",
    "        column_amount = len(context.value.split(\",\"))\n",
    "        context.emit(\"aantal_kolommen\", column_amount)\n",
    "    \n",
    "class MyReducer(api.Reducer):\n",
    "    # Alleen aantal_kolommen reducen met max()\n",
    "    def reduce(self, context):\n",
    "        if(context.key == 'aantal_kolommen'):\n",
    "            context.emit(context.key, max(context.values))\n",
    "\n",
    "FACTORY = pipes.Factory(MyMapper, reducer_class=MyReducer)        \n",
    "        \n",
    "def main():\n",
    "    pipes.run_task(FACTORY)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d23359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r /Oefeningen/Project/oef1\n",
    "!pydoop submit --upload-file-to-cache stap_1_analytics.py stap_1_analytics /Oefeningen/Project/cleaned.csv /Oefeningen/Project/oef1 --entry-point main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbf4672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bestandsgrootte: 1.9 MB\n",
      "Aantal replicas: 1\n",
      "Aantal blokken: 1\n",
      "--------------\n",
      "Aantal replicas na het te verhoogen: 3\n"
     ]
    }
   ],
   "source": [
    "# bestandsgrootte netter maken (thx chatgpt :P)\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Y', suffix)\n",
    "\n",
    "# file size, replica amount en block amount\n",
    "path = \"/Oefeningen/Project/cleaned.csv\"\n",
    "path_info = client.get_path_info(path)\n",
    "\n",
    "size = (sizeof_fmt(path_info['size']))\n",
    "\n",
    "print('Bestandsgrootte: {}'.format(size))\n",
    "print('Aantal replicas: {}'.format(path_info['replication']))\n",
    "aantal_blokken = math.ceil(path_info['size'] / path_info['block_size'])\n",
    "print('Aantal blokken: {}'.format(aantal_blokken))\n",
    "\n",
    "# replica nu verhogen met 2 (1+2=3)\n",
    "client.set_replication(path, 3)\n",
    "\n",
    "# checken of replicas verhoogd is effectief\n",
    "print('--------------')\n",
    "path_info = client.get_path_info(path) # path info opnieuw ophalen anders is de path_info nog niet bijgewerkt na de replications wel bij te werken\n",
    "print('Aantal replicas na het te verhoogen: {}'.format(path_info['replication']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d21d8",
   "metadata": {},
   "source": [
    "**Antwoord:**  \n",
    "Bestandsgrootte: 1.9 MB  \n",
    "Aantal replicas: 3  \n",
    "Aantal blokken: 1\n",
    "  \n",
    "Aantal replicas na het te verhoogen: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f7893e",
   "metadata": {},
   "source": [
    "\n",
    "Voorzie code om de output directory te verwijderen om niet steeds een andere naam te moeten kiezen in de cell met commentaar \"# hdfs deel 2\".\n",
    "\n",
    "Schrijf in een **aparte file** met naam **stap_2_analytics.py** een  mapreduce applicatie die de volgende gegevens berekend van de dataset.\n",
    "Eventueel mag deze file aangemaakt worden via een cell hieronder\n",
    "* Het aantal rijen in de dataset\n",
    "* Het aantal verschillende woorden, verwijder hiervoor alle karakters die geen letter zijn en maak geen onderscheid tussen upper en lowercase waarden\n",
    "* Het aantal labels van elke klasse aanwezig in de dataset. Hoeveel klassen zijn er aanwezig en zijn ze reeds geencodeerd.\n",
    "* De maximum, minimum en gemiddelde lengte van de tekst aanwezig in de dataset.\n",
    "* Een histogram van het aantal woorden per rij. Zorg ervoor dat er minstens 5 bins aanwezig zijn maar indien je een dataset met lange tekst hebt mag dit meer zijn om een duidelijke histogram te krijgen.\n",
    "* Emit ook de grenzen van de bins\n",
    "* Bereken ook het aantal missing values die in je dataset aanwezig zijn.\n",
    "* Voorzie ook een counter om de vooruitgang van de applicatie te tracken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2e9e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stap_2_analytics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stap_2_analytics.py\n",
    "\n",
    "#hdfs deel 2\n",
    "\n",
    "import pydoop.mapreduce.api as api\n",
    "import pydoop.mapreduce.pipes as pipes\n",
    "import statistics\n",
    "\n",
    "unieke_woorden_set = set()\n",
    "\n",
    "class MyMapper(api.Mapper):\n",
    "    def __init__(self, context):\n",
    "        super(MyMapper, self).__init__(context)\n",
    "        context.set_status(\"initializing mapper\")\n",
    "        self.input_words = context.get_counter(\"WORDCOUNT\", \"INPUT_WORDS\")\n",
    "        \n",
    "    def map(self, context):\n",
    "\n",
    "        # Aantal rijen\n",
    "        context.emit(\"Aantal_rijen\", 1)\n",
    "\n",
    "        # Aantal verschillende woorden\n",
    "        rijen = context.value.split(\",\")\n",
    "        woorden = rijen[6].split(\" \")\n",
    "        for woord in woorden:\n",
    "            context.emit(\"Woord\", woord)\n",
    "            print(woord)\n",
    "        \n",
    "        # Min/max/gem lengte van de tekst \n",
    "        context.emit(\"Lengte\", len(woorden))\n",
    "                \n",
    "        # Histogram (min aantal woorden is 1 en max aantal woorden is 34, dus we gaan bins maken per stapjes van 5)             \n",
    "        # De grenzen van de bins zitten in de key, bv bin_1_5 is de bin van 1 tot en met 5.\n",
    "        if(len(woorden) <= 5):\n",
    "            context.emit(\"bin_1_5\", 1)\n",
    "        if(len(woorden) > 5 and len(woorden) <= 10):\n",
    "            context.emit(\"bin_6_10\", 1)\n",
    "        if(len(woorden) > 10 and len(woorden) <= 15):\n",
    "            context.emit(\"bin_11_15\", 1)          \n",
    "        if(len(woorden) > 15 and len(woorden) <= 20):\n",
    "            context.emit(\"bin_16_20\", 1) \n",
    "        if(len(woorden) > 20 and len(woorden) <= 25):\n",
    "            context.emit(\"bin_21_25\", 1) \n",
    "        if(len(woorden) > 25 and len(woorden) <= 30):\n",
    "            context.emit(\"bin_26_30\", 1) \n",
    "        if(len(woorden) > 30 and len(woorden) <= 35):\n",
    "            context.emit(\"bin_31_35\", 1)    \n",
    "\n",
    "        # Lege of whitespace velden tellen\n",
    "        for item in rijen:\n",
    "            if item is None or item == \"\":\n",
    "                context.emit(\"Lege_velden\", 1)\n",
    "                \n",
    "        context.increment_counter(self.input_words, len(woorden))\n",
    "                \n",
    "            \n",
    "            \n",
    "class MyReducer(api.Reducer):\n",
    "    def __init__(self, context):\n",
    "        super(MyReducer, self).__init__(context)\n",
    "        context.set_status(\"initializing reducer\")\n",
    "        self.output_words = context.get_counter(\"WORDCOUNT\", \"OUTPUT_WORDS\")\n",
    "        \n",
    "    global unieke_woorden_set\n",
    "    def reduce(self, context):\n",
    "         \n",
    "        # Aantal rijen\n",
    "        if(context.key == 'Aantal_rijen'):\n",
    "            context.emit(context.key, sum(context.values))\n",
    "            \n",
    "        # Aantal verschillende woorden\n",
    "        if(context.key == 'Woord'):\n",
    "            unique_values = {}\n",
    "\n",
    "            for value in context.values:\n",
    "                unique_values[value] = True\n",
    "\n",
    "            count = len(unique_values)\n",
    "            context.emit(\"Aantal verschillende woorden\", count)\n",
    "\n",
    "       # Min/max/gem lengte van de text\n",
    "        if(context.key == 'Lengte'):\n",
    "            valuesfix = list(context.values)\n",
    "            context.emit((context.key + '_min'), min(valuesfix))\n",
    "            context.emit((context.key + '_max'), max(valuesfix))\n",
    "            context.emit((context.key + '_gem'), statistics.mean(valuesfix))\n",
    "            \n",
    "        # Histogram\n",
    "        if(context.key == \"bin_1_5\"):\n",
    "            context.emit(\"bin_1_5\", sum(context.values)) \n",
    "        if(context.key == \"bin_6_10\"):\n",
    "            context.emit(\"bin_6_10\", sum(context.values))      \n",
    "        if(context.key == \"bin_11_15\"):\n",
    "            context.emit(\"bin_11_15\", sum(context.values))   \n",
    "        if(context.key == \"bin_16_20\"):\n",
    "            context.emit(\"bin_16_20\", sum(context.values))             \n",
    "        if(context.key == \"bin_21_25\"):\n",
    "            context.emit(\"bin_21_25\", sum(context.values))\n",
    "        if(context.key == \"bin_26_30\"):\n",
    "            context.emit(\"bin_26_30\", sum(context.values))\n",
    "        if(context.key == \"bin_31_35\"):\n",
    "            context.emit(\"bin_31_35\", sum(context.values))\n",
    "            \n",
    "        # Lege of whitespace velden tellen\n",
    "        if(context.key == 'Lege_velden'):\n",
    "            context.emit(context.key, sum(context.values))    \n",
    "            \n",
    "        context.increment_counter(self.output_words, 1)\n",
    "\n",
    "FACTORY = pipes.Factory(MyMapper, reducer_class=MyReducer)        \n",
    "        \n",
    "def main():\n",
    "    pipes.run_task(FACTORY)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44a31a15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/Oefeningen/Project/oef2': No such file or directory\n",
      "2023-05-03 19:33:19,051 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2023-05-03 19:33:21,211 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2023-05-03 19:33:21,625 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/bigdata/.staging/job_1683135043100_0001\n",
      "2023-05-03 19:33:21,782 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2023-05-03 19:33:21,812 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2023-05-03 19:33:21,874 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "2023-05-03 19:33:22,052 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1683135043100_0001\n",
      "2023-05-03 19:33:22,053 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2023-05-03 19:33:22,142 INFO mapred.YARNRunner: Job jar is not present. Not adding any jar to the list of resources.\n",
      "2023-05-03 19:33:22,177 INFO conf.Configuration: found resource resource-types.xml at file:/home/bigdata/hadoop/etc/hadoop/resource-types.xml\n",
      "2023-05-03 19:33:22,185 INFO resource.ResourceUtils: Adding resource type - name = vram, units = G, type = COUNTABLE\n",
      "2023-05-03 19:33:22,516 INFO impl.YarnClientImpl: Submitted application application_1683135043100_0001\n",
      "2023-05-03 19:33:22,547 INFO mapreduce.Job: The url to track the job: http://bigdata-VirtualBox:8088/proxy/application_1683135043100_0001/\n",
      "2023-05-03 19:33:22,547 INFO mapreduce.Job: Running job: job_1683135043100_0001\n",
      "2023-05-03 19:33:28,604 INFO mapreduce.Job: Job job_1683135043100_0001 running in uber mode : false\n",
      "2023-05-03 19:33:28,604 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2023-05-03 19:33:35,645 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2023-05-03 19:33:39,658 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2023-05-03 19:33:40,666 INFO mapreduce.Job: Job job_1683135043100_0001 completed successfully\n",
      "2023-05-03 19:33:40,722 INFO mapreduce.Job: Counters: 56\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1109583\n",
      "\t\tFILE: Number of bytes written=2757699\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1957481\n",
      "\t\tHDFS: Number of bytes written=225\n",
      "\t\tHDFS: Number of read operations=9\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=4557\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2378\n",
      "\t\tTotal time spent by all map tasks (ms)=4557\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2378\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=4557\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2378\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=4666368\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=2435072\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=0\n",
      "\t\tMap output records=397181\n",
      "\t\tMap output bytes=15484181\n",
      "\t\tMap output materialized bytes=1109575\n",
      "\t\tInput split bytes=117\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=11\n",
      "\t\tReduce shuffle bytes=1109575\n",
      "\t\tReduce input records=397181\n",
      "\t\tReduce output records=13\n",
      "\t\tSpilled Records=794362\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=44\n",
      "\t\tCPU time spent (ms)=3560\n",
      "\t\tPhysical memory (bytes) snapshot=582934528\n",
      "\t\tVirtual memory (bytes) snapshot=5495111680\n",
      "\t\tTotal committed heap usage (bytes)=775946240\n",
      "\t\tPeak Map Physical memory (bytes)=345686016\n",
      "\t\tPeak Map Virtual memory (bytes)=2746679296\n",
      "\t\tPeak Reduce Physical memory (bytes)=237248512\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2748432384\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tWORDCOUNT\n",
      "\t\tINPUT_WORDS=322809\n",
      "\t\tOUTPUT_WORDS=11\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=225\n",
      "INFO:PydoopSubmitter:Done\n"
     ]
    }
   ],
   "source": [
    "# dit commando kan gebruikt worden om de applicatie uit te voeren (pas het pad aan indien de notebook server niet draait in de directory van het project)\n",
    "!hdfs dfs -rm -r /Oefeningen/Project/oef2\n",
    "!pydoop submit --upload-file-to-cache stap_2_analytics.py stap_2_analytics /Oefeningen/Project/cleaned.csv /Oefeningen/Project/oef2 --entry-point main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7a272e",
   "metadata": {},
   "source": [
    "Download via python code in onderstaande cell de output van de map-reduce taak in de cell met de commentaar \"#hdfs deel 3\".\n",
    "Bewaar dit bestand met de naam \"output_stap_2.txt\".\n",
    "Print de antwoorden op de vragen berekend via de mapreduce applicatie en plot ook de histogram. \n",
    "Sla deze figuur ook op als een png met de naam \"histogram_stap_2.png\".\n",
    "Zorg ervoor dat deze bestanden mee ingediend worden door ze toe te voegen aan git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a8db5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal verschillende woorden\t19065\n",
      "Lengte_min\t1\n",
      "Lengte_max\t34\n",
      "Lengte_gem\t13.02489509360878\n",
      "bin_1_5\t3627\n",
      "bin_6_10\t6857\n",
      "bin_11_15\t5663\n",
      "bin_16_20\t4274\n",
      "bin_21_25\t3122\n",
      "bin_26_30\t1156\n",
      "bin_31_35\t85\n",
      "Lege_velden\t20\n",
      "Aantal_rijen\t24784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hdfs deel 3\n",
    "if os.path.exists(\"part-r-00000\"):\n",
    "    os.remove(\"part-r-00000\")\n",
    "    \n",
    "if os.path.exists(\"output_stap_2.txt\"):\n",
    "    os.remove(\"output_stap_2.txt\")    \n",
    "    \n",
    "src_hdfs_path = \"hdfs://localhost:9000/Oefeningen/Project/oef2/part-r-00000\"\n",
    "dest_path = \"\" # lege dest path geeft zorgt ervoor dat die in de map wordt geplaatst waar de ipynb zich bevind en dat is wat we nodig hebben\n",
    "hdfs.get(src_hdfs_path, dest_path)\n",
    "os.rename('part-r-00000','output_stap_2.txt')\n",
    "\n",
    "with open('output_stap_2.txt', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3b08517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>aantal_woorden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as a woman you shouldn t complain about cleani...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy dats cold tyga dwn bad for cuffin dat hoe ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dawg you ever fuck a bitch and she start to cr...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she look like a tranny</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the shit you hear about me might be true or it...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>you s a muthaf in lie right his tl is trash no...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>you ve gone and broke the wrong heart baby and...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat dat nigguh like i aint fu...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>ruffled ntac eileen dahlia beautiful color com...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  aantal_woorden\n",
       "0      as a woman you shouldn t complain about cleani...              23\n",
       "1      boy dats cold tyga dwn bad for cuffin dat hoe ...              14\n",
       "2      dawg you ever fuck a bitch and she start to cr...              16\n",
       "3                                 she look like a tranny               5\n",
       "4      the shit you hear about me might be true or it...              22\n",
       "...                                                  ...             ...\n",
       "24778  you s a muthaf in lie right his tl is trash no...              17\n",
       "24779  you ve gone and broke the wrong heart baby and...              14\n",
       "24780  young buck wanna eat dat nigguh like i aint fu...              13\n",
       "24781              youu got wild bitches tellin you lies               7\n",
       "24782  ruffled ntac eileen dahlia beautiful color com...              15\n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_plot = df.copy()\n",
    "df_plot[\"aantal_woorden\"] = [len(x.split()) for x in df[\"tweet\"].tolist()]\n",
    "display(df_plot[[\"tweet\",\"aantal_woorden\"]])\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(15)\n",
    "f.set_figheight(9)\n",
    "\n",
    "plt.hist(df_plot[\"aantal_woorden\"], bins=35, edgecolor='black', linewidth=1)  # density=False would make counts\n",
    "plt.ylabel('Aantal tweets')\n",
    "plt.xlabel('Aantal woorden')\n",
    "\n",
    "plt.title(\"Histogram aantal woorden per tweet (DataFrame)\")\n",
    "\n",
    "plt.savefig('histogram_stap_2_dataframe.png')\n",
    "\n",
    "plt.show()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbfc7a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = []\n",
    "values = []\n",
    "\n",
    "file1 = open('output_stap_2.txt', 'r')\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    count += 1\n",
    " \n",
    "    line = file1.readline()\n",
    " \n",
    "    if(line.startswith(\"bin\")):\n",
    "            lines_split = line.split()\n",
    "            bin_n = lines_split[0]\n",
    "            value_n = lines_split[1]\n",
    "            \n",
    "            bin_n_split = bin_n.split(\"_\")\n",
    "            bin_grenzen = [int(bin_n_split[1]), int(bin_n_split[2])]\n",
    "            bins.append(bin_grenzen)\n",
    "            \n",
    "            values.append(int(value_n))\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "\n",
    "file1.close()\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(9)\n",
    "\n",
    "ax.set_xlim(left = 0, right = np.amax(bins))\n",
    "ax.set_ylim(bottom = 0, top = np.amax(values))\n",
    "\n",
    "for x in range(len(values)):   \n",
    "    ax.add_patch(Rectangle((bins[x][0]-1, 0), 5, values[x], edgecolor='black', linewidth=1))\n",
    "    \n",
    "plt.xlabel(\"Aantal woorden\")\n",
    "plt.ylabel(\"Aantal tweets\")\n",
    "\n",
    "plt.title(\"Histogram aantal woorden per tweet (MapReduce)\")\n",
    "\n",
    "plt.savefig('histogram_stap_2_mapreduce.png')\n",
    "\n",
    "plt.show()\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98dc823",
   "metadata": {},
   "source": [
    "## Stap 3: Verwerken van de dataset en trainen ML-model\n",
    "\n",
    "Nu we een beter inzicht hebben over de inhoud van de dataset is het mogelijk om via een (py)Spark Applicatie deze dataset te verwerken en een ML-model te trainen.\n",
    "Schrijf alle code voor deze stap in een **aparte** python file met naam **stap_3_training.py**.\n",
    "Zorg opnieuw voor voldoende commentaar en een duidelijke code structuur.\n",
    "\n",
    "Maak hiervoor een Spark pipeline aan die de volgende stappen uitvoert.\n",
    "* Omzetten tekst naar bag of words\n",
    "* Zet de bag of words om naar een vector op basis van de TFIDF (Term Frequency Inverse Document Frequency Transformer).\n",
    "* Maak een pipeline aan met een Gradient Boosted tree classification model. Doe gridsearch om de ideale hyperparameters te vinden en zorg ervoor dat er een outputkolom is met de voorspelde sentimenten (niet enkel de labels)\n",
    "* Hou ook de benodigde trainingstijd bij!\n",
    "* Bereken de accuraatheid en precision en recall op de testdata en maak een confusion-matrix\n",
    "* Sla het ML-model op in de **Project** directory.\n",
    " \n",
    "**Bespreek hieronder de code en de gemaakte keuzes. Beantwoord minstens onderstaande vragen**\n",
    "* Uit welke stappen bestaat de pijplijn en wat voeren deze uit op je dataset.\n",
    "* Welke hyperparameters geven het beste resultaat? Wat is de betekenis van deze hyperparameters? \n",
    "* Evalueer het model, gaat het de verschillende klasses even goed voorspellen/classificeren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d1ae97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stap_3_training.py\n"
     ]
    }
   ],
   "source": [
    "%%file stap_3_training.py\n",
    "import time\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").config('spark.executor.memory', '4g').appName(\"Project\").getOrCreate()\n",
    "\n",
    "# df inlezen als sparkdf van csv\n",
    "spark_df = spark.read.option(\"header\",True).csv(\"/Oefeningen/Project/cleaned.csv\")\n",
    "\n",
    "# 20 null rijen droppen en van multiclass naar binary\n",
    "spark_df = spark_df.filter(spark_df.tweet.isNotNull())\n",
    "spark_df = spark_df.withColumn(\"class\", col(\"class\").cast(IntegerType()))\n",
    "spark_df = spark_df.filter((col(\"class\") == 1) | (col(\"class\") == 2))\n",
    "spark_df = spark_df.withColumn(\"class\", when(col(\"class\") == 2, 0).otherwise(col(\"class\")))\n",
    "# nu is 0 = neutral en 1 = offensive\n",
    "\n",
    "# train test split\n",
    "train_data, test_data = spark_df.select(\"tweet\", \"class\").randomSplit([0.7, 0.3], seed=420)\n",
    "\n",
    "# pipeline\n",
    "tokenizer = RegexTokenizer(inputCol=\"tweet\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "gbt = GBTClassifier(labelCol=\"class\", featuresCol=\"features\")\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, gbt])\n",
    "\n",
    "# create grid of hyperparameters for grid search\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [2, 4, 6]) \\\n",
    "    .addGrid(gbt.maxBins, [20, 30, 40]) \\\n",
    "    .addGrid(gbt.maxIter, [10, 20, 30]) \\\n",
    "    .addGrid(gbt.stepSize, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "# create evaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"class\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# create cross validator with 5-fold cross validation\n",
    "cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# fit the model\n",
    "model = cv.fit(train_data)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Total training time: {:.2f} seconds\".format(end_time - start_time))\n",
    "best_pipeline_model = model.bestModel\n",
    "best_pipeline_model.save('/Oefeningen/Project/bestmodel')\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fce2556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/07 14:54:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/07 14:55:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/05/07 14:55:38 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/07 14:55:38 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "Total training time: 16450.19 seconds                                           \n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# execute stap 3\n",
    "!python stap_3_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722d6e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark2 = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").config('spark.executor.memory', '4g').appName(\"Project2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaadbe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9509679242616929\n",
      "Weighted Precision = 0.9595008562312446\n",
      "Weighted Precision = 0.9509679242616929\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters model:\n",
      "maxDepth: 6\n",
      "maxBins: 20\n",
      "maxIter: 30\n",
      "stepSize: 0.1\n"
     ]
    }
   ],
   "source": [
    "# omdat train test gesplitst is in een appart python file waar we nu niet meer\n",
    "# aankunnen moeten we enkele stappen opnieuw doen:\n",
    "\n",
    "loaded_pipeline_model = PipelineModel.load('/Oefeningen/Project/bestmodel')\n",
    "\n",
    "spark_df = spark2.read.option(\"header\",True).csv(\"/Oefeningen/Project/cleaned.csv\")\n",
    "\n",
    "# 20 null rijen droppen en van multiclass naar binary\n",
    "spark_df = spark_df.filter(spark_df.tweet.isNotNull())\n",
    "spark_df = spark_df.withColumn(\"class\", col(\"class\").cast(IntegerType()))\n",
    "spark_df = spark_df.filter((col(\"class\") == 1) | (col(\"class\") == 2))\n",
    "spark_df = spark_df.withColumn(\"class\", when(col(\"class\") == 2, 0).otherwise(col(\"class\")))\n",
    "# nu is 0 = neutral en 1 = offensive\n",
    "\n",
    "# train test split\n",
    "train_data, test_data = spark_df.select(\"tweet\", \"class\").randomSplit([0.7, 0.3], seed=420)\n",
    "# zelfde percentages en seed dus zal exact zoals in apart python file gesplitst worden\n",
    "\n",
    "predictions = loaded_pipeline_model.transform(test_data)\n",
    "predictions = predictions.withColumn(\"class\", col(\"class\").cast(\"double\"))\n",
    "\n",
    "predictions = predictions.withColumnRenamed(\"class\", \"label\")\n",
    "\n",
    "predictions_and_labels = predictions.select(\"prediction\", \"label\").rdd\n",
    "predictions_and_labels = predictions_and_labels.map(lambda x: (x.prediction, x.label))\n",
    "\n",
    "metrics = MulticlassMetrics(predictions_and_labels)\n",
    "\n",
    "accuracy = metrics.accuracy\n",
    "print(\"Accuracy = %s\" % accuracy)\n",
    "weightedPrecision = metrics.weightedPrecision\n",
    "print(\"Weighted Precision = %s\" % weightedPrecision)\n",
    "weightedRecall = metrics.weightedRecall\n",
    "print(\"Weighted Precision = %s\" % weightedRecall)\n",
    "\n",
    "confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "classes = [str(i) for i in range(confusion_matrix.shape[0])]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(confusion_matrix, cmap='Blues')\n",
    "\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_yticks(np.arange(len(classes)))\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticklabels(classes)\n",
    "ax.set_xlabel('Predicted label')\n",
    "ax.set_ylabel('True label')\n",
    "ax.xaxis.set_tick_params(rotation=90)\n",
    "\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "thresh = confusion_matrix.max() / 2\n",
    "for i in range(confusion_matrix.shape[0]):\n",
    "    for j in range(confusion_matrix.shape[1]):\n",
    "        ax.text(j, i, format(confusion_matrix[i, j], '.0f'),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if confusion_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "gbt_model = loaded_pipeline_model.stages[-1]\n",
    "\n",
    "assert isinstance(gbt_model, GBTClassificationModel)\n",
    "\n",
    "print(\"Parameters model:\")\n",
    "params = gbt_model.extractParamMap()\n",
    "print(\"maxDepth:\", params[gbt_model.maxDepth])\n",
    "print(\"maxBins:\", params[gbt_model.maxBins])\n",
    "print(\"maxIter:\", params[gbt_model.maxIter])\n",
    "print(\"stepSize:\", params[gbt_model.stepSize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3bc00f",
   "metadata": {},
   "source": [
    "### Stappen pipeline:\n",
    "- RegexTokenizer: tekstinput (tweet) wordt getokeniseerd in individuele woorden op basis van een reguliere expressie.\n",
    "- StopWordsRemover: verwijdert veelvoorkomende stopwoorken uit de getokeniseerde woorden.\n",
    "- CountVectorizer: converteert de getokeniseerde en gefilterde woorden naar een matrix van woordentellingen.\n",
    "- IDF: Past de inverse document frequentie (IDF) transformatie toe op de woordentellingsmatrix. \\\n",
    "De laatste twee stappen kunnen aanschouwd worden als TF-IDF.\n",
    "- GBTClassifier: dan het uiteindelijke machine learning gedeelte. Een gradient boosted tree classifier die zal trainen om de tweets te voorspellen op neutrale tekst of beledigend taalgebruik.\n",
    "\n",
    "### Beste hyperparameters & uitleg:\n",
    "- maxDepth: 6: dit bepaalt de maximale diepte van de decision tree. Het is het aantal lagen van de boom. Een hogere waarde kan leiden tot een meer complexe tree die beter past bij de trainingsgegevens, maar kan ook overfitting veroorzaken.\n",
    "- maxBins: 20: dit bepaalt het maximum aantal bins dat wordt gebruikt om continue functies in te delen bij het opbouwen van de decision tree. Een hogere waarde kan leiden tot meer nauwkeurigheid, maar kan ook de prestaties van het algoritme verminderen.\n",
    "- maxIter: 30: dit bepaalt het maximale aantal iteraties (boosting-rondes) dat wordt uitgevoerd om de prestaties van het model te verbeteren.\n",
    "- stepSize: 0.1: dit bepaalt de grootte van de stap die wordt genomen bij het updaten van de gewichten van de bomen tijdens elke iteratie. Het is de leersnelheid. Een lagere waarde kan leiden tot langzamere, maar stabielere convergentie.\n",
    "\n",
    "### Evaluatie:\n",
    "- Het model lijkt ten eerste een zeer hoge score te behalen maar dit is natuurlijk een gevolg van de dataset die vrij ongebalanceerd is. Hier kunnen we niet veel aan doen omdat we dit vrij laat door hadden dus om nu nog met een andere dataset te gaan werken = onbegonnen werk. En de sataset gebalanceerd maken zorgt ervoor dat er meer als de helft van de data verloren gaat dus dat is ook niet ideaal voor de accuraatheid. Maar over het algemeen is het model meer als ok voor ons doel. In de voorspellingen is 0 = neutraal en 1 = offensive language, je zou het model dus kunnen gebruiken niet als strict classificerend maar eerder als waarschuwend van pas op, het kan zijn dat deze tekst offensive language bevat. Op die manier zal zij heel vaak juist zijn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab64363",
   "metadata": {},
   "source": [
    "## Stap 4: Binnenhalen en verwerken live data met een streaming framework\n",
    "\n",
    "In de les hebben we drie verschillende manieren gezien om data via Streams binnen te halen.\n",
    "Bespreek hier kort de drie technieken (Spark Streaming, Kafka, Storm) en licht de punten toe waarop ze gelijkaardig zijn of verschillen. Geef ook aan welke keuze je maakt en waarom? (Mogelijke redenen zijn bijvoorbeeld de verschillen eerder besproken, je eigen gevoel bij de techniek of een goede tutorial die je gevonden hebt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7ae51",
   "metadata": {},
   "source": [
    "Bespreek de technieken hier en licht je keuze toe:\n",
    "\n",
    "- Storm is een realtime verwerkingsplatform dat is ontworpen om grote hoeveelheden realtime gegevens te verwerken en te analyseren. Het ondersteunt meerdere programmeertalen, zoals Java en Python, en biedt een hoge doorvoer en lage latentie. Storm is ideaal voor toepassingen die gericht zijn op het uitvoeren van realtime analyses en het nemen van beslissingen op basis van die analyses.\n",
    "\n",
    "- Spark Streaming maakt deel uit van het Spark-ecosysteem dat is ontworpen om realtime gegevens te verwerken door batchverwerking te simuleren met microbatches. Het ondersteunt integratie met verschillende gegevensbronnen zoals Kafka, Flume en Twitter, en heeft een hoge beschikbaarheid en fouttolerantie. Spark Streaming is met name geschikt voor toepassingen gericht op batchanalyse, machine learning en real-time datastreaminganalyse.\n",
    "\n",
    "- Kafka is een gedistribueerd berichtensysteem dat in realtime gegevens verzamelt en opslaat uit verschillende bronnen, zoals sensoren, mobiele apparaten en websites. Het ondersteunt hoge schaalbaarheid, beschikbaarheid en betrouwbaarheid. Kafka kan worden geïntegreerd met verschillende verwerkingsframeworks zoals Spark en Storm.\n",
    "\n",
    "Wij gaan gebruik maken van Kafka omdat die beschrijving het best past bij de doelstelling van het project en omdat we er al ervaring mee hebben door de streaming taak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4642b490",
   "metadata": {},
   "source": [
    "**Implementeren applicatie voor binnenhalen social media data en doorsturen naar pyspark streaming in de file stap_4_query_reddit.py**\n",
    "\n",
    "Implementeer nu de code om data van Reddit binnen te halen.\n",
    "Voer hiervoor de volgende stappen uit:\n",
    "* Installeer de praw python package ([bron](https://praw.readthedocs.io/en/stable/getting_started/installation.html))\n",
    "* Voer minstens de pre-requisites uit die je kan vinden in de [quick-start guide](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)\n",
    "    * Indien er gevraagd wordt naar url/uri kan je linken naar http://www.google.be\n",
    "    * Het client id staat naast onder de tekst \"personal use script\"\n",
    "* Schrijf nu een reddit **read-only** python applicatie die comments uitleest, hierbij let je best op de volgende zaken:\n",
    "    * Kies een relevante subreddit(s) die je uitleest (bvb over bepaalde nieuwsbronnen/politieke kanalen/favoriete serie of game/ .... Je kan ook kiezen om alle berichten te lezen door middel van het keyword \"all\".\n",
    "    * Bekijk enkel comments die minstens 10 woorden bevatten (dus enkel alfabetische karakters).\n",
    "    * Zorg ervoor dat alles lowercase is.\n",
    "    * Let erop dat je comments bekijkt en geen submissions.\n",
    "    * Bekijk ook de tutorial voor [een bot](https://praw.readthedocs.io/en/stable/tutorials/reply_bot.html) die alle submissions leest.\n",
    "    * Het is de bedoeling dat deze applicatie niet stopt van zichzelf. (Manueel kan je het steeds stoppen met Ctrl + C)\n",
    "* **Debugging stap (niet nodig in finale versie)**: Print de binnenkomende comments uit, zorg dat er minstens af en to een nieuwe comment binnenkomt. Anders kies je best wat extra subreddits om te monitoren.\n",
    "* Schrijf elke comment in een aparte json-file en plaats deze in een folder op het hdfs. De filename mag het id zijn van het comment. In de json-files moet de volgende data zitten voor elke comment:\n",
    "    * het ID\n",
    "    * de tekst in de comment\n",
    "\n",
    "**Let op: dit script moet in een terminal gestart worden om de notebook niet te blokkeren**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca33b97b",
   "metadata": {},
   "source": [
    "\n",
    "**Antwoord:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install python praw package\n",
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51629aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stap_4_query_reddit.py\n"
     ]
    }
   ],
   "source": [
    "%%file stap_4_query_reddit.py\n",
    "import praw\n",
    "import re\n",
    "import json\n",
    "import pydoop.hdfs as hdfs\n",
    "\n",
    "print(\"Deleting existing comments in folder\")\n",
    "files = hdfs.ls(\"/Oefeningen/Project/Comments/\")\n",
    "for file in files:\n",
    "    hdfs.rmr(file)\n",
    "\n",
    "# Preprocessing van de text (zelfde code als in begin van het project)\n",
    "def preprocess_tweet_text(tweet):\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    tweet = tweet.replace(\"&amp;\", \"and\")\n",
    "    tweet = re.sub(r\"@[^\\s]+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"#(\\w+)\", \"\", tweet)\n",
    "    tweet = re.sub(r\"(^|\\s)RT(\\s|$)\", \" \", tweet)\n",
    "    tweet = tweet.encode(\"ascii\", \"ignore\").decode()\n",
    "    emoji_pattern = re.compile(\"[\" u\"\\U0001F600-\\U0001F64F\" u\"\\U0001F300-\\U0001F5FF\" u\"\\U0001F680-\\U0001F6FF\" u\"\\U0001F1E0-\\U0001F1FF\" u\"\\U00002702-\\U000027B0\" u\"\\U000024C2-\\U0001F251\" \"]+\", flags=re.UNICODE)\n",
    "    tweet = emoji_pattern.sub(r\"\", tweet)\n",
    "    tweet = re.sub(r\"[^a-zA-Z0-9]\", \" \", tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"\\s+\", \" \", tweet).strip()\n",
    "    return tweet\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"co084F0-3Ny8mDHZe0nSfw\",\n",
    "    client_secret=\"0_ri6wpokDxDoUXL_5IHv2gCaEDfug\",\n",
    "    user_agent=\"linuxvm:projectbigdataquintenlorenzo:v1.0.0\",\n",
    "    password=\"nCqarxBZ8n2eKLr\",\n",
    "    username=\"Illustrious-Ant9761\",\n",
    ")\n",
    "\n",
    "reddit.read_only = True\n",
    "\n",
    "# enkele subreddits genomen waar volgens:\n",
    "# https://maxcandocia.com/article/2017/Jan/31/which-subreddits-swear-the-most/\n",
    "# vaak in de comments gescholden wordt, als we andere gaan nemen kan het zijn dat we niet meteen\n",
    "# veel offensive language comments vinden want er staan vast filters op wat je kan commenten op reddit\n",
    "\n",
    "subreddit = reddit.subreddit(\"videos+The_Donald+tifu+news+Documentaries+AskReddit+worldnews+pics\")\n",
    "\n",
    "print(\"Writing comments to HDFS\")\n",
    "for comment in subreddit.stream.comments():\n",
    "    cleanedcomment = preprocess_tweet_text(comment.body)\n",
    "    if(len(cleanedcomment.split())>10):\n",
    "        commentobj = {\n",
    "          \"id\": comment.id,\n",
    "          \"tweet\": cleanedcomment,\n",
    "        }\n",
    "        jsoncomment = json.dumps(commentobj, ensure_ascii=False)\n",
    "        with hdfs.open(f\"/Oefeningen/Project/Comments/{comment.id}.json\", \"w\") as f:\n",
    "            f.write(jsoncomment.encode(\"utf-8\"))\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82759f45",
   "metadata": {},
   "source": [
    "**Implementeren applicatie voor verwerken tweets in de file stap_4_process_reddit.py**\n",
    "\n",
    "Schrijf een spark streaming applicatie die de volgende stappen uitvoert:\n",
    "* Maak een streaming spark applicatie aan dat de directory monitors waar de comments worden opgeslagen\n",
    "* Laad het getrainde model in met de ML-pipeline als een broadcast variabele\n",
    "* Zorg ervoor dat de frequentie waarin de data gechecked wordt 30 seconden is.\n",
    "* Stuur de text van de ontvangen comment door de ML-pipeline en classificeer elke comment\n",
    "* Print per verwerkte batch een dataframe met het aantal comments geclassificeerd per klasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfeabb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stap_4_process_reddit.py\n"
     ]
    }
   ],
   "source": [
    "%%file stap_4_process_reddit.py\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"CommentClassification\").getOrCreate()\n",
    "\n",
    "# Load the trained model from the ML pipeline\n",
    "model_path = '/Oefeningen/Project/bestmodel'\n",
    "model = PipelineModel.load(model_path)\n",
    "\n",
    "# Define the input directory where comments are stored\n",
    "input_directory = '/Oefeningen/Project/Comments/'\n",
    "\n",
    "# Set the streaming interval to 30 seconds\n",
    "streaming_interval = \"30 seconds\"\n",
    "\n",
    "# Define a schema for the JSON data\n",
    "schema = StructType().add(\"id\", StringType()).add(\"tweet\", StringType())\n",
    "\n",
    "# Create a streaming DataFrame by monitoring the input directory\n",
    "comments_df = spark.readStream.schema(schema).json(input_directory)\n",
    "\n",
    "# Apply the model to classify each comment\n",
    "classified_df = model.transform(comments_df)\n",
    "\n",
    "# Select the required columns\n",
    "result_df = classified_df.select(\"id\", \"tweet\", \"prediction\")\n",
    "\n",
    "# Define a function to process each batch\n",
    "def process_batch(batch_df, batch_id):\n",
    "    # Count the number of predictions for class 0 and class 1\n",
    "    class_0_count = batch_df.filter(batch_df.prediction == 0).count()\n",
    "    class_1_count = batch_df.filter(batch_df.prediction == 1).count()\n",
    "    \n",
    "    # Create a DataFrame with class and count information\n",
    "    count_df = spark.createDataFrame([(batch_id, class_0_count, class_1_count)], [\"BatchID\", \"Class0Count\", \"Class1Count\"])\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    count_df.show()\n",
    "\n",
    "# Start the streaming query and process each batch\n",
    "query = result_df.writeStream.outputMode(\"append\").foreachBatch(process_batch).trigger(processingTime=streaming_interval).start()\n",
    "\n",
    "# Wait for the streaming to finish\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8158b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/21 21:00:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "WARNING: An illegal reflective access operation has occurred                    \n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/bigdata/anaconda3/lib/python3.8/site-packages/pyspark/jars/spark-core_2.12-3.3.2.jar) to field java.math.BigInteger.mag\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/05/21 21:00:57 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-57af019d-3843-4fdc-bc86-4d94d3b5b766. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "23/05/21 21:00:57 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "23/05/21 21:00:59 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/21 21:00:59 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "+-------+-----------+-----------+\n",
      "|BatchID|Class0Count|Class1Count|\n",
      "+-------+-----------+-----------+\n",
      "|      0|        141|          5|\n",
      "+-------+-----------+-----------+\n",
      "\n",
      "+-------+-----------+-----------+\n",
      "|BatchID|Class0Count|Class1Count|\n",
      "+-------+-----------+-----------+\n",
      "|      1|         36|          0|\n",
      "+-------+-----------+-----------+\n",
      "\n",
      "+-------+-----------+-----------+\n",
      "|BatchID|Class0Count|Class1Count|\n",
      "+-------+-----------+-----------+\n",
      "|      2|         26|          2|\n",
      "+-------+-----------+-----------+\n",
      "\n",
      "+-------+-----------+-----------+\n",
      "|BatchID|Class0Count|Class1Count|\n",
      "+-------+-----------+-----------+\n",
      "|      3|         38|          6|\n",
      "+-------+-----------+-----------+\n",
      "\n",
      "+-------+-----------+-----------+\n",
      "|BatchID|Class0Count|Class1Count|\n",
      "+-------+-----------+-----------+\n",
      "|      4|         31|          4|\n",
      "+-------+-----------+-----------+\n",
      "\n",
      "^C\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=4>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/pyspark/context.py\", line 362, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/pyspark/context.py\", line 1447, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 190, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o13.sc\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "Traceback (most recent call last):\n",
      "  File \"stap_4_process_reddit.py\", line 48, in <module>\n",
      "    query.awaitTermination()\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/pyspark/sql/streaming.py\", line 107, in awaitTermination\n",
      "    return self._jsq.awaitTermination()\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 190, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/home/bigdata/anaconda3/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o310.awaitTermination\n"
     ]
    }
   ],
   "source": [
    "!python stap_4_process_reddit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41726f",
   "metadata": {},
   "source": [
    "## Stap 5: Opslaan in NoSQL database\n",
    "\n",
    "In de les hebben we een aantal locally hosted NoSQL databases besproken. \n",
    "In dit project ga je gebruik maken van MongoDB. \n",
    "\n",
    "Geef een korte beschrijving van dit type database. Van welk type NoSQL database is MongoDB een implementatie? Wat zijn de belangrijkste termen die gebruikt worden in MongoDb om de datastructuur te definieren? Hoe wordt de data gestructureerd in MongoDB?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad6fa6",
   "metadata": {},
   "source": [
    "**Antwoord:**\\\n",
    "MongoDB is een documentgeoriënteerde database die behoort tot het type NoSQL-databases. In tegenstelling tot traditionele relationele databases, maakt MongoDB geen gebruik van tabellen en rijen, maar organiseert het gegevens in flexibele documenten die JSON-achtige structuren gebruiken.\n",
    "\n",
    "MongoDB is specifiek een implementatie van een documentdatabase, wat betekent dat het is ontworpen om documenten op te slaan en te beheren. Documenten in MongoDB zijn opgebouwd uit velden en waarden, vergelijkbaar met de sleutel-waardeparen in JSON. Een verzameling van documenten wordt opgeslagen in een collectie.\n",
    "\n",
    "De belangrijkste termen die worden gebruikt in MongoDB om de datastructuur te definiëren zijn:\n",
    "\n",
    "Document: Een document is de basisgegevenseenheid in MongoDB. Het is een set van velden met bijbehorende waarden. Documenten worden opgeslagen in BSON (Binary JSON) formaat, dat een binair coderingsschema is voor representatie van JSON-achtige documenten.\n",
    "\n",
    "Collectie: Een collectie is een groep van gerelateerde documenten in MongoDB. Het kan worden gezien als een equivalent van een tabel in een relationele database. Collecties bevatten documenten met verschillende structuren en schema's.\n",
    "\n",
    "Veld: Een veld is een individuele eenheid binnen een document die een bepaalde waarde bevat. Elk veld heeft een naam en een waarde die kan bestaan uit verschillende datatypen, zoals strings, getallen, booleans, arrays, ingebedde documenten, enz.\n",
    "\n",
    "Sleutel: Een sleutel is een speciaal veld in een document dat als unieke identificator fungeert voor dat document binnen een collectie. Het wordt vaak \"_id\" genoemd en kan handmatig worden toegewezen of automatisch gegenereerd worden door MongoDB.\n",
    "\n",
    "Query: Een query is een instructie om documenten te vinden of op te halen uit een collectie op basis van bepaalde criteria. MongoDB ondersteunt een krachtige querytaal die het mogelijk maakt om te zoeken op velden, waarden, bereik, logische operatoren en meer.\n",
    "\n",
    "Over het algemeen wordt de data in MongoDB gestructureerd in een flexibel, hiërarchisch formaat met behulp van documenten. Hierdoor kunnen ontwikkelaars complexe datastructuren maken zonder vooraf een strikt schema te definiëren, waardoor het eenvoudig is om wijzigingen in de datastructuur aan te brengen.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc3dcd2",
   "metadata": {},
   "source": [
    "**Pas nu de applicaties aan uit stap 4.**\n",
    "\n",
    "Pas de code uit **stap_4_query_reddit.py** aan en bewaar deze in een file met naam **stap_5_query_reddit.py**.\n",
    "Zorg er hierbij voor dat zeker de volgende zaken ook worden opgeslagen in de json van elke comment:\n",
    "* De naam van de auteur die het gepost heeft\n",
    "* Het aantal replies op de comment\n",
    "* De score van de comment\n",
    "* Het aantal comments in de submission waartoe de comment hoort\n",
    "* De score van de submission waartoe de comment behoort\n",
    "* Een timestamp (bewaar dit als getal en zet het later voor naar mongodb geschreven wordt om naar een datetime)\n",
    "\n",
    "Ook de code uit **stap_4_process_reddit.py** moet aangepast worden.\n",
    "Na het classificeren van elke comment moeten we de resultaten nu opslaan in een mongoDB database.\n",
    "Voeg de code toe aan het bestand **stap_5_process_reddit.py** om de nodige databases/collecties/... aan te maken.\n",
    "Sla alle waarden in de json op in de MongoDB database en zorg er ook voor dat de zelf uitgevoerde classificatie toegevoegd wordt aan de database. Meer informatie kan je [hier](https://www.mongodb.com/docs/spark-connector/current/structured-streaming/#stream-to-mongodb-from-a-csv-file) vinden. Indien er problemen zijn met class-not-found errors mag je ook gebruik maken van de foreach methode in de datastreamwriter klasse van pyspark.\n",
    "\n",
    "Bespreek hieronder hoe je de data gestructureerd hebt om het op te slaan. Welke waarden zijn je key(s)? Waarom heb je deze gekozen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0939d9",
   "metadata": {},
   "source": [
    "Bespreek de gebruikte datastructuur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9dd954ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stap_5_query_reddit.py\n"
     ]
    }
   ],
   "source": [
    "%%file stap_5_query_reddit.py\n",
    "\n",
    "import praw\n",
    "import re\n",
    "import json\n",
    "import pydoop.hdfs as hdfs\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Deleting existing comments in folder\")\n",
    "files = hdfs.ls(\"/Oefeningen/Project/Comments/\")\n",
    "for file in files:\n",
    "    hdfs.rmr(file)\n",
    "\n",
    "# Preprocessing van de text (zelfde code als in begin van het project)\n",
    "def preprocess_tweet_text(tweet):\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    tweet = tweet.replace(\"&amp;\", \"and\")\n",
    "    tweet = re.sub(r\"@[^\\s]+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"#(\\w+)\", \"\", tweet)\n",
    "    tweet = re.sub(r\"(^|\\s)RT(\\s|$)\", \" \", tweet)\n",
    "    tweet = tweet.encode(\"ascii\", \"ignore\").decode()\n",
    "    emoji_pattern = re.compile(\"[\" u\"\\U0001F600-\\U0001F64F\" u\"\\U0001F300-\\U0001F5FF\" u\"\\U0001F680-\\U0001F6FF\" u\"\\U0001F1E0-\\U0001F1FF\" u\"\\U00002702-\\U000027B0\" u\"\\U000024C2-\\U0001F251\" \"]+\", flags=re.UNICODE)\n",
    "    tweet = emoji_pattern.sub(r\"\", tweet)\n",
    "    tweet = re.sub(r\"[^a-zA-Z0-9]\", \" \", tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub(r\"\\s+\", \" \", tweet).strip()\n",
    "    return tweet\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"co084F0-3Ny8mDHZe0nSfw\",\n",
    "    client_secret=\"0_ri6wpokDxDoUXL_5IHv2gCaEDfug\",\n",
    "    user_agent=\"linuxvm:projectbigdataquintenlorenzo:v1.0.0\",\n",
    "    password=\"nCqarxBZ8n2eKLr\",\n",
    "    username=\"Illustrious-Ant9761\",\n",
    ")\n",
    "\n",
    "reddit.read_only = True\n",
    "\n",
    "# enkele subreddits genomen waar volgens:\n",
    "# https://maxcandocia.com/article/2017/Jan/31/which-subreddits-swear-the-most/\n",
    "# vaak in de comments gescholden wordt, als we andere gaan nemen kan het zijn dat we niet meteen\n",
    "# veel offensive language comments vinden want er staan vast filters op wat je kan commenten op reddit\n",
    "\n",
    "subreddit = reddit.subreddit(\"videos+The_Donald+tifu+news+Documentaries+AskReddit+worldnews+pics\")\n",
    "\n",
    "print(\"Writing comments to HDFS\")\n",
    "for comment in subreddit.stream.comments():\n",
    "    cleaned_comment = preprocess_tweet_text(comment.body)\n",
    "    if len(cleaned_comment.split()) > 10:\n",
    "        try:\n",
    "            comment = reddit.comment(comment.id)\n",
    "            comment.refresh()\n",
    "            comment.replies.replace_more()\n",
    "            replies = comment.replies.__len__()\n",
    "            comment_obj = {\n",
    "                \"id\": comment.id,\n",
    "                \"author\": comment.author.name,\n",
    "                \"tweet\": cleaned_comment,\n",
    "                \"replies\": replies,\n",
    "                \"score\": comment.score,\n",
    "                \"submission_comment_count\": comment.submission.num_comments,\n",
    "                \"submission_score\": comment.submission.score,\n",
    "                \"timestamp\": comment.created_utc\n",
    "            }\n",
    "            json_comment = json.dumps(comment_obj, ensure_ascii=False)\n",
    "            with hdfs.open(f\"/Oefeningen/Project/Comments/{comment.id}.json\", \"w\") as f:\n",
    "                f.write(json_comment.encode(\"utf-8\"))\n",
    "                f.close()\n",
    "        except Exception as e:\n",
    "            print(f\"[{datetime.now()}] An error occurred: {str(e)}, comment skipped\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5044844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stap_5_process_reddit.py\n"
     ]
    }
   ],
   "source": [
    "%%file stap_5_process_reddit.py\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"CommentClassification\").getOrCreate()\n",
    "\n",
    "# Load the trained model from the ML pipeline\n",
    "model_path = '/Oefeningen/Project/bestmodel'\n",
    "model = PipelineModel.load(model_path)\n",
    "\n",
    "# Define the input directory where comments are stored\n",
    "input_directory = '/Oefeningen/Project/Comments/'\n",
    "\n",
    "# Set the streaming interval to 30 seconds\n",
    "streaming_interval = \"30 seconds\"\n",
    "\n",
    "# Define a schema for the JSON data\n",
    "schema = StructType().add(\"id\", StringType()).add(\"author\", StringType()).add(\"tweet\", StringType()).add(\"replies\", IntegerType()).add(\"score\", IntegerType()).add(\"submission_comment_count\", IntegerType()).add(\"submission_score\", IntegerType()).add(\"timestamp\", DoubleType ())\n",
    "\n",
    "# Create a streaming DataFrame by monitoring the input directory\n",
    "comments_df = spark.readStream.schema(schema).json(input_directory)\n",
    "\n",
    "# Apply the model to classify each comment\n",
    "classified_df = model.transform(comments_df)\n",
    "\n",
    "# Select the required columns\n",
    "result_df = classified_df.select(\"id\", \"author\", \"tweet\", \"replies\", \"score\", \"submission_comment_count\", \"submission_score\", \"timestamp\", \"prediction\")\n",
    "\n",
    "# Define the output directory for the JSON file\n",
    "output_directory = './'\n",
    "\n",
    "# Define the JSON file name\n",
    "json_file_name = 'result.json'\n",
    "\n",
    "# Define a function to write rows as JSON objects to a file\n",
    "def write_json_file(rows):\n",
    "    # Create an empty list to store JSON objects\n",
    "    json_objects = []\n",
    "    \n",
    "    # Iterate over each row and convert it to a JSON object\n",
    "    for row in rows:\n",
    "        json_objects.append(row.asDict())\n",
    "    \n",
    "    # Define the file path for the JSON file\n",
    "    json_file_path = os.path.join(output_directory, json_file_name)\n",
    "    \n",
    "    # Check if the JSON file exists\n",
    "    if os.path.exists(json_file_path):\n",
    "        # Read the existing contents of the file\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            existing_json_objects = json_file.readlines()\n",
    "        \n",
    "        # Append the new JSON objects to the existing ones\n",
    "        json_objects = existing_json_objects + [json.dumps(json_object) + '\\n' for json_object in json_objects]\n",
    "    \n",
    "    # Write the JSON objects to the file\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        for json_object in json_objects:\n",
    "            json_file.write(json_object)\n",
    "\n",
    "# Define a function to process each batch\n",
    "def process_batch(batch_df, batch_id):\n",
    "    # Count the number of predictions for class 0 and class 1\n",
    "    class_0_count = batch_df.filter(batch_df.prediction == 0).count()\n",
    "    class_1_count = batch_df.filter(batch_df.prediction == 1).count()\n",
    "    \n",
    "    # Create a DataFrame with class and count information\n",
    "    count_df = spark.createDataFrame([(batch_id, class_0_count, class_1_count)], [\"BatchID\", \"Class0Count\", \"Class1Count\"])\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    count_df.show()\n",
    "    \n",
    "    # Input moest 'tweet' kolom hebben als text voor prediction maar nu renamen we die naar 'text'\n",
    "    batch_df = batch_df.withColumnRenamed(\"tweet\", \"text\")\n",
    "    batch_df.show()\n",
    "   \n",
    "    # Write the rows as JSON objects to the file\n",
    "    write_json_file(batch_df.collect())\n",
    "\n",
    "\n",
    "# Start the streaming query and process each batch\n",
    "query = result_df.writeStream.outputMode(\"append\").foreachBatch(process_batch).trigger(processingTime=streaming_interval).start()\n",
    "\n",
    "# Wait for the streaming to finish\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d17527a",
   "metadata": {},
   "source": [
    "Voor er verdergegaan wordt naar de laatste stap, gebruik een methode via de terminal om te verifieren of je data goed wordt opgeslaan. \n",
    "Print daarvoor bijvoorbeeld het aantal records aanwezig in de NoSQL-Database uit. \n",
    "Beschrijf hieronder de gevolgde werkwijze en maak een screenshot van de terminal met je uitgevoerde commando's.\n",
    "Sla dit screenshot op onder de naam **stap_5_num_records.png**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c214a",
   "metadata": {},
   "source": [
    "**Beschrijving werkwijze:**\n",
    "\n",
    "Beschrijf hier je werkwijze. Vergeet niet het screenshot te maken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3578f5",
   "metadata": {},
   "source": [
    "## Stap 6: Lezen vanuit NoSQL database\n",
    "\n",
    "Om het project af te ronden gaan we nu een aantal zaken uitlezen uit de NoSQL-database om de werking van de applicatie te monitoren. \n",
    "Maak hiervoor een aparte python file **stap_6_readNoSQL.py**.\n",
    "Om voor voldoende records te zorgen, laat de scriptjes uit stap 5 lang genoeg lopen om minstens 200 resultaten te hebben.\n",
    "\n",
    "Nu gaan er een aantal zaken opgevraagd moeten worden uit de database en geplot moeten worden.\n",
    "Probeer hierbij zoveel mogelijk in het gekozen database systeem te werken en niet eerst alles uit te lezen in Spark.\n",
    "Na het berekenen van de waarden kan je kiezen welke python tool je gebruikt voor de visualisaties uit te voeren.\n",
    "Welke plot je gebruikt is vrij te kiezen maar zorg ervoor dat wat er getoond moet worden eenvoudig afgelezen kan worden (Let hierbij op grootte van de figuur, aantal elementen op de assen en een legende).\n",
    "Sla ook elke figuur op in een **.png** bestand. Maak deze figuren leesbaar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb305e2",
   "metadata": {},
   "source": [
    "**Haal het totaal aantal comments op dat geclassificeerd werd in elke klasse (stap_6_fig_1.png).**\n",
    "* Hier wil ik dus bvb. zien dat als je drie klasses hebt -> er zijn er 100 in klasse 1, 60 in klasse 2, 70 in klasse 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f2cbc",
   "metadata": {},
   "source": [
    "**Toon een scatterplot met op de x-as het aantal comments van de submission, op de y-as de score van de submission en de classificatie als kleur (stap_6_fig_2.png). Horen positieve of negatieve comments vaker bij populaire submissions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff075c",
   "metadata": {},
   "source": [
    "**Toon een histogram met het aantal comments per gebruiker. (stap_6_fig_3.png)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6f24c",
   "metadata": {},
   "source": [
    "**Zorg er nu voor dat je met de code van stap 5 comments hebt verzamelt van minstens 5 verschillende uren. Bereken nu met commando's naar het NoSQL-database systeem om het percentage comments geclassificeerd in elke klasse te berekenen per dag. Er gaan dus per uur x waarden geplot moeten worden met x je aantal klassen. Sla dit resultaat op in stap_6_fig_4.png**\n",
    "\n",
    "**Is er een verband tussen het gemiddeld aantal comments van de verschillende klassen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f8adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file stap_6_readNoSQL.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8a59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python stap_6_readNoSQL.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ad361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
